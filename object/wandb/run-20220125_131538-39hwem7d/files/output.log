                 from  n    params  module                                  arguments
  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]
  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]
  2                -1  1     18816  models.common.C3                        [64, 64, 1]
  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]
  4                -1  2    115712  models.common.C3                        [128, 128, 2]
  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]
  6                -1  3    625152  models.common.C3                        [256, 256, 3]
  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]
  8                -1  1   1182720  models.common.C3                        [512, 512, 1]
  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]
 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]
 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']
 12           [-1, 6]  1         0  models.common.Concat                    [1]
 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]
 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]
 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']
 16           [-1, 4]  1         0  models.common.Concat                    [1]
 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]
 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]
 19          [-1, 14]  1         0  models.common.Concat                    [1]
 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]
 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]
 22          [-1, 10]  1         0  models.common.Concat                    [1]
 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]
 24      [17, 20, 23]  1     18879  models.yolo.Detect                      [2, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]
Model Summary: 270 layers, 7025023 parameters, 7025023 gradients, 15.9 GFLOPs
module 'signal' has no attribute 'SIGALRM'
Transferred 342/349 items from pretrained\yolov5s.pt
Scaled weight_decay = 0.0005
[34m[1moptimizer:[39m[22m SGD with parameter groups 57 weight, 60 weight (no decay), 60 bias
[34m[1mtrain: [39m[22mScanning 'D:\smart_traffic\yolov5\data\mask\labels\train.cache' images and labels... 379 found, 0 missing, 0 empty, 1 corrupted: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 380/380 [00:00<?, ?it/s]
[34m[1mtrain: [39m[22mWARNING: D:\smart_traffic\yolov5\data\mask\images\train\face149.jpg: ignoring corrupt image/label: cannot identify image file 'D:\\smart_traffic\\yolov5\\data\\mask\\images\\train\\face149.jpg'
[34m[1mtrain: [39m[22mWARNING: D:\smart_traffic\yolov5\data\mask\images\train\face195.jpg: corrupt JPEG restored and saved
[34m[1mtrain: [39m[22mWARNING: D:\smart_traffic\yolov5\data\mask\images\train\face201.jpg: corrupt JPEG restored and saved
[34m[1mtrain: [39m[22mWARNING: D:\smart_traffic\yolov5\data\mask\images\train\face228.jpg: corrupt JPEG restored and saved
[34m[1mtrain: [39m[22mWARNING: D:\smart_traffic\yolov5\data\mask\images\train\face243.jpg: corrupt JPEG restored and saved
[34m[1mtrain: [39m[22mWARNING: D:\smart_traffic\yolov5\data\mask\images\train\masks_00106.jpg: corrupt JPEG restored and saved
[34m[1mtrain: [39m[22mWARNING: D:\smart_traffic\yolov5\data\mask\images\train\masks_0012.jpg: corrupt JPEG restored and saved
[34m[1mtrain: [39m[22mWARNING: D:\smart_traffic\yolov5\data\mask\images\train\masks_0032.jpg: corrupt JPEG restored and saved
[34m[1mtrain: [39m[22mWARNING: D:\smart_traffic\yolov5\data\mask\images\train\masks_0054.jpg: corrupt JPEG restored and saved
[34m[1mtrain: [39m[22mWARNING: D:\smart_traffic\yolov5\data\mask\images\train\masks_0057.jpg: corrupt JPEG restored and saved
[34m[1mtrain: [39m[22mWARNING: D:\smart_traffic\yolov5\data\mask\images\train\masks_0077.jpg: corrupt JPEG restored and saved
[34m[1mtrain: [39m[22mWARNING: D:\smart_traffic\yolov5\data\mask\images\train\masks_0078.jpg: corrupt JPEG restored and saved
[34m[1mtrain: [39m[22mWARNING: D:\smart_traffic\yolov5\data\mask\images\train\masks_009.jpg: corrupt JPEG restored and saved
[34m[1mval: [39m[22mScanning 'D:\smart_traffic\yolov5\data\mask\labels\val.cache' images and labels... 10 found, 0 missing, 0 empty, 0 corrupted: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<?, ?it/s]
[34m[1mval: [39m[22mWARNING: D:\smart_traffic\yolov5\data\mask\images\val\masks_00129.jpg: corrupt JPEG restored and saved
[34m[1mAutoAnchor: [39m[22m4.26 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset
Image sizes 640 train, 640 val
Using 0 dataloader workers
Logging results to [1mruns\train\exp11
Starting training for 100 epochs...
     Epoch   gpu_mem       box       obj       cls    labels  img_size









      0/99    0.946G    0.1158   0.03305   0.02803        10       640:  14%|â–ˆâ–Ž        | 13/95 [00:22<02:21,  1.73s/it]
Traceback (most recent call last):
  File "train.py", line 636, in <module>
    main(opt)
  File "train.py", line 533, in main
    train(opt.hyp, opt, device, callbacks)
  File "train.py", line 341, in train
    scaler.step(optimizer)  # optimizer.step
  File "G:\conda\envs\alphapose\lib\site-packages\torch\cuda\amp\grad_scaler.py", line 338, in step
    retval = self._maybe_opt_step(optimizer, optimizer_state, *args, **kwargs)
  File "G:\conda\envs\alphapose\lib\site-packages\torch\cuda\amp\grad_scaler.py", line 284, in _maybe_opt_step
    if not sum(v.item() for v in optimizer_state["found_inf_per_device"].values()):
  File "G:\conda\envs\alphapose\lib\site-packages\torch\cuda\amp\grad_scaler.py", line 284, in <genexpr>
    if not sum(v.item() for v in optimizer_state["found_inf_per_device"].values()):
KeyboardInterrupt